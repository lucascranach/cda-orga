---
layout: simple
title:  "Roadmap AMI Tasks 2023"
subtitle: "Was passiert seitens des Advanced Media Institutes?"
---

Jorge ist noch bis Ende Juli dabei (11-12 Wochen x 8h = 88-96h). Markus und Yannic hoffentlich ab Juni. Volker und Christian bis zum Lebensende.

## Priorisierung

### Prio 1

- Neugestaltung Archivalienmodul: liegt im internen Bereich auf dem [neuen Server](http://srvneu.lucascranach.org/de/intern/search/?kind=archivals) und dem [alten Server](http://lucascranach.org/de/intern/search/?kind=archivals)
- Neugestaltung Literaturmodul: liegt im internen Bereich auf dem [neuen Server](http://srvneu.lucascranach.org/de/intern/search/?kind=literature_references) und dem [alten Server](http://srvneu.lucascranach.org/de/intern/search/?kind=literature_references)
- Erweiterung um Publikationsfilter
- Zusammenstellung einer Übersicht aller öffentlich verwendeten URLs, über die man von extern auf lucascranach.org kommt zur korrekten Weiterleitung auf die neuen Module und Objektseiten
- Serverumzug
- Dokumentation der Datenbeschaffenheit und -struktur (XML -> JSON)
- Dokumentation der Filterpflege

### Prio 2
- Tool zur Bildbeschriftung im Adminbereich
- Bugs/Anpassungen (Github) und Exporte
- Einfügen der Overall_Overview Abbildungen
- Optimierung und Vereinfachung des aktuellen Importers
- Ingest Prozess optimieren

### Prio 3
- Geographical Mapping

## Aktueller Stand und Überlegungen

### Prio 1

**Archivalien- und Literaturmodul** liegen im internen Bereich zum Testen vor.
Einzig beim Literaturmodul steht aktuell noch die korrekte Ausgabe der sauberen Publikationstypen + Filterung anhand von Publikationstypen an. Dafür muss zum einen der Importer minimal angepasst werden, um die Daten für die Weiternutzung soweit aufzubereiten, wie mit Jana in der Mail-Konversation vom 20. - 26.04. abgestimmt.

Wenn möglich, fände ich es sinnvoll, die beiden Module noch soweit zu bringen, dass sie für die Öffentlichkeit live geschaltet werden können. Der Grund hierfür ist, dass mit dem Serverumzug auch der Umzug der "alten" Module zumsammenhängt. Dies bedeutet wiederum, dass auch die alte `sqlImport`-Tabelle und natürlich auch die ganzen für die Module relevanten Ordner und PHP-Skripte migriert werden müssen. Bei den PHP-Skripten sind leider auch (kleinere) Anpassungen notwendig, damit diese mit PHP 8.2 arbeiten können (Verwendung von alten deprecated Funktionen). Aus Kompatibilitätsgründen muss man auf dem neuen Server wahrscheinlich weiter auf Apache httpd und eine ähnliche Ordnerstruktur wie auf dem aktuellen Produktivsystem setzen. Aktuell läuft dort ein nginx + php-fastCGI.

Mit dem Sprung auf die neuen Module, sollten Direktaufrufe der Module über alte URL-Muster abgefangen und korrekt weitergeleitet werden. Meiner Meinung nach wäre es nicht verkehrt eine **Übersicht über URLs** aufzustellen, um sicher zu gehen, dass diese auch auf dem neuen Server die korrekten Bereiche/Ressourcen von lucascranach.org adressieren. Abhängig davon ob doch noch die alten Module auf den neuen Server migriert werden, müsste man sich hier dann früher oder später so oder so Gedanken machen, wie weitergeleitet werden soll, wenn die Module in die Suche-Applikation integriert werden.

Für den **Serverumzug** muss zudem noch geplant werden, wie der Sprung genau stattfinden soll. Denke hierbei an die großen Bilddatenmengen und wie das Einbinden dieser auf dem neuen Server aussehen wird. Hierzu habe ich keinen Überblick über die relevanten Daten und welche technischen Möglichkeiten sich anbieten würden, um die großen Bildmengen bereits jetzt parallel zum aktuellen Produktivsystem auch auf dem neuen Server bereit zu stellen, um auch dort die volle Funktionalität der Suche und der Objektseiten testen zu können, bevor der Sprung auf das neue System stattfindet.

Eine weitere Notwendigkeit ist die **Dokumentation** der Daten und ihrer Struktur in der Form wie wir sie erhalten aber auch wie bestimmte Informationen kodiert sind (z.B. wie übersetzte Werte hinterlegt sind und wie sie weiterverarbeitet werden können). Bedeutet was mit Jana und Helen abgemacht wurde, wie Daten im TMS eingegeben werden. Darunter fallen auch "Abmachungen" bzw. Daten-"Verträge", von vor meiner Zeit beim CDA-Projekt. Weiter sollte auch die Pflege der Filter dokumentiert und evtl. auch weiter vereinfacht werden (Katalog, Zuschreibung und Sammlung / Standort).

### Prio 2

Zum **Tool zur Bildbeschriftung im Adminbereich** kann ich nicht sehr viel sagen. Ich gehe aber davon aus, dass es nur die Objektseitenebene betrifft. Da Bildbeschriftungen dynamisch ergänzt werden, müssten diese wahrscheinlich auch dynamisch abgefragt und ausgegeben werden. Meines Wissens nach, werden die Beschriftungen für ein Bild aktuell noch über den Importer abgefragt und dann mit in den JSONs abgelegt. Das Tool kann evtl. auf Objektseitenebene aufgebaut werden z.B. nur im internen Bereich verfügbar und nutzbar. Die Beschriftungen können dann evtl. über die API persistiert und abgefragt werden. Im Hintergrund könnte es dann vllt. in der Mongo-DB abgelegt werden, die Volker bereits für die JWT-Authentication integriert hat (liegt noch als PullRequest vor).

Zu den weiteren Punkten unter Prio 2 kann ich nur zum **Importer-Punkt** etwas sagen. Da bin ich nämlich aktuell dabei diesen etwas zu überarbeiten, damit bestimmte Funktionen stärker von außen über Parameter gesteuert werden können. Aber auch der interne Code-Aufbau wird gerade überarbeitet, damit klarer ist, von wo die Rohdaten kommen (XML-Dateien), wie sie "fließen", wie sie aggregiert werden und wo sie ihr Ziel finden (JSON-Dateien).

### Prio 3

Zu dem Thema **Geographical Mapping** kann ich leider nicht viel sagen, habe mir aber schon ein wenig die [Ergebnisse aus dem Screendesign-Modul](https://th-koeln.github.io/mi-bachelor-screendesign-projekte/) angesehen.
Der Importer reichert Artefakte mit Location-Informationen aktuell bereits um GeoPosition-Daten (Breiten- und Längengrad) an. Diese Daten werden anhand der getty-URL bzw. TGN-ID und mit Hilfe des getty.edu-Sparql-Endpunkts abgefragt. Der dafür relevante Code findet sich im [Locations-Modul](https://github.com/lucascranach/importer/tree/master/src/Modules/Locations) des Importers. Das Einzeichnen von Artefaktpositionen auf einer Karte ist somit schon mal möglich, da die dafür notwendigen GeoPosition-Daten vorliegen.

Für die Integration in die Suche muss sehr wahrscheinlich die API erweitert werden. Da man es mit recht vielen Locations zu tun hat, muss wahrscheinlich bereits auf API-Ebene ein Clustering der Locations stattfinden, um initial nicht zu viele Daten abfragen und in die Karte einzeichnen zu müssen. Evtl. bietet hier Elasticsearch das eine oder andere Feature von Haus aus an. Interessanter könnte aber das Kartenmaterial sein und worauf man hierfür zurückgreift. Vllt. reicht es bereits die Weltkarte bis zu einem ausreichend tiefen Zoomlevel (grobe Länderkarte) anzubieten, wodurch man wahrscheinlich in der Lage sein wird, das Kartenmaterial selbst anbieten zu können. Entweder als vorgenerierte Kacheln oder als Vektordaten (GeoJSON). Als Quelle würde sich dann OpenStreetMap (https://openmaptiles.org/ o. https://tilemaker.org/) anbieten.
